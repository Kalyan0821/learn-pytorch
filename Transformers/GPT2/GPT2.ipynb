{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch import nn\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPT2 Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='gpt2', vocab_size=50257, model_max_len=1024, is_fast=False, padding_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", \n",
    "                                          bos_token=\"<|startoftext|>\",  # Use in input computations\n",
    "                                          eos_token=\"<|endoftext|>\",    # Use in loss computations\n",
    "                                          pad_token=\"<|pad|>\")          # Don't use in any computations\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2_vocab/vocab.json', './gpt2_vocab/merges.txt')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"./gpt2_vocab\"):\n",
    "    os.makedirs(\"./gpt2_vocab\")\n",
    "tokenizer.save_vocabulary(\"./gpt2_vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257 50256 50258\n",
      "<|startoftext|> <|endoftext|> <|pad|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id)\n",
    "print(tokenizer.bos_token, tokenizer.eos_token, tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftext|>Hello. BERT provides contextualized word embeddings.<|endoftext|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sequence = \"Hello. BERT provides contextualized word embeddings.\"\n",
    "example_sequence = tokenizer.bos_token + example_sequence + tokenizer.eos_token\n",
    "example_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50257, 15496, 13, 347, 17395, 3769, 38356, 1143, 1573, 11525, 67, 654, 13, 50256, 50258, 50258, 50258, 50258] \n",
      "\n",
      "['<|startoftext|>', 'Hello', '.', 'ĠB', 'ERT', 'Ġprovides', 'Ġcontextual', 'ized', 'Ġword', 'Ġembed', 'd', 'ings', '.', '<|endoftext|>', '<|pad|>', '<|pad|>', '<|pad|>', '<|pad|>']\n"
     ]
    }
   ],
   "source": [
    "# Sequence: a b c d, max_seq_len=8\n",
    "# Desired tokenization: <BOS> a b c d <EOS> <PAD> <PAD>\n",
    "# Labels to provide:    <BOS> a b c d <EOS> -100  -100  (left-shifting will be done automatically)\n",
    "#                                                       (\"-100\" means ignore training loss from those outputs)  \n",
    "\n",
    "ids = tokenizer.encode(example_sequence,\n",
    "                       add_special_tokens=True,\n",
    "                       padding=\"max_length\",\n",
    "                       truncation=True,\n",
    "                       max_length=18)\n",
    "print(ids, '\\n')\n",
    "print(tokenizer.convert_ids_to_tokens(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eminem Lyrics Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album_Name</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Album_URL</th>\n",
       "      <th>Views</th>\n",
       "      <th>Release_date</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Alfred (Intro)</td>\n",
       "      <td>[Intro: Alfred Hitchcock]\\nThus far, this albu...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>24.3K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Black Magic</td>\n",
       "      <td>[Chorus: Skylar Grey &amp; Eminem]\\nBlack magic, n...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>180.6K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Alfred’s Theme</td>\n",
       "      <td>[Verse 1]\\nBefore I check the mic (Check, chec...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>285.6K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Tone Deaf</td>\n",
       "      <td>[Intro]\\nYeah, I'm sorry (Huh?)\\nWhat did you ...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>210.9K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Book of Rhymes</td>\n",
       "      <td>[Intro]\\nI don't smile, I don't frown, get too...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>193.3K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Unreleased Songs</td>\n",
       "      <td>Listen To Your Heart</td>\n",
       "      <td>[Chorus: Roxette]\\nI know there's something in...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Unreleased-songs</td>\n",
       "      <td>65.5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Unreleased Songs</td>\n",
       "      <td>I Get Money (Remix)</td>\n",
       "      <td>[Intro]\\nYeah, yeah, I get it\\nI run this rap ...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Unreleased-songs</td>\n",
       "      <td>28.5K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Unreleased Songs</td>\n",
       "      <td>Cut Back</td>\n",
       "      <td>[Verse]\\nI cut back on the syllables just a li...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Unreleased-songs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Unreleased Songs</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>[Intro]\\nC'mon!\\n\\n[Verse]\\nI still remember t...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Unreleased-songs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Unreleased Songs</td>\n",
       "      <td>Everything I Do</td>\n",
       "      <td>[Intro]\\nCDs ain't selling no more anyways, ma...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Unreleased-songs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Album_Name             Song_Name  \\\n",
       "0    Music To Be Murdered By: Side B        Alfred (Intro)   \n",
       "1    Music To Be Murdered By: Side B           Black Magic   \n",
       "2    Music To Be Murdered By: Side B        Alfred’s Theme   \n",
       "3    Music To Be Murdered By: Side B             Tone Deaf   \n",
       "4    Music To Be Murdered By: Side B        Book of Rhymes   \n",
       "..                               ...                   ...   \n",
       "343                 Unreleased Songs  Listen To Your Heart   \n",
       "344                 Unreleased Songs   I Get Money (Remix)   \n",
       "345                 Unreleased Songs              Cut Back   \n",
       "346                 Unreleased Songs               Hip Hop   \n",
       "347                 Unreleased Songs       Everything I Do   \n",
       "\n",
       "                                                Lyrics  \\\n",
       "0    [Intro: Alfred Hitchcock]\\nThus far, this albu...   \n",
       "1    [Chorus: Skylar Grey & Eminem]\\nBlack magic, n...   \n",
       "2    [Verse 1]\\nBefore I check the mic (Check, chec...   \n",
       "3    [Intro]\\nYeah, I'm sorry (Huh?)\\nWhat did you ...   \n",
       "4    [Intro]\\nI don't smile, I don't frown, get too...   \n",
       "..                                                 ...   \n",
       "343  [Chorus: Roxette]\\nI know there's something in...   \n",
       "344  [Intro]\\nYeah, yeah, I get it\\nI run this rap ...   \n",
       "345  [Verse]\\nI cut back on the syllables just a li...   \n",
       "346  [Intro]\\nC'mon!\\n\\n[Verse]\\nI still remember t...   \n",
       "347  [Intro]\\nCDs ain't selling no more anyways, ma...   \n",
       "\n",
       "                                             Album_URL   Views  \\\n",
       "0    https://genius.com/albums/Eminem/Music-to-be-m...   24.3K   \n",
       "1    https://genius.com/albums/Eminem/Music-to-be-m...  180.6K   \n",
       "2    https://genius.com/albums/Eminem/Music-to-be-m...  285.6K   \n",
       "3    https://genius.com/albums/Eminem/Music-to-be-m...  210.9K   \n",
       "4    https://genius.com/albums/Eminem/Music-to-be-m...  193.3K   \n",
       "..                                                 ...     ...   \n",
       "343  https://genius.com/albums/Eminem/Unreleased-songs   65.5K   \n",
       "344  https://genius.com/albums/Eminem/Unreleased-songs   28.5K   \n",
       "345  https://genius.com/albums/Eminem/Unreleased-songs     NaN   \n",
       "346  https://genius.com/albums/Eminem/Unreleased-songs     NaN   \n",
       "347  https://genius.com/albums/Eminem/Unreleased-songs     NaN   \n",
       "\n",
       "          Release_date Unnamed: 6  \n",
       "0    December 18, 2020        NaN  \n",
       "1    December 18, 2020        NaN  \n",
       "2    December 18, 2020        NaN  \n",
       "3    December 18, 2020        NaN  \n",
       "4    December 18, 2020        NaN  \n",
       "..                 ...        ...  \n",
       "343                NaN        NaN  \n",
       "344                NaN        NaN  \n",
       "345               2007        NaN  \n",
       "346               2007        NaN  \n",
       "347                NaN        NaN  \n",
       "\n",
       "[348 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./Eminem_Lyrics.csv\", sep='\\t', encoding=\"cp1252\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2105 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2309"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_songs = (tokenizer.bos_token + df_train[\"Lyrics\"] + tokenizer.eos_token).values\n",
    "\n",
    "required_max = max([len(tokenizer.encode(song)) for song in train_songs])\n",
    "required_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalyan/.virtualenvs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_input_ids = tokenizer.batch_encode_plus(train_songs,\n",
    "                                              add_special_tokens=True,\n",
    "                                              padding=\"max_length\",\n",
    "                                              truncation=True,\n",
    "                                              max_length=512,  # To fit in GPU\n",
    "                                              return_attention_mask=False,\n",
    "                                              return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "train_labels = torch.tensor(train_input_ids)\n",
    "train_labels[train_labels==tokenizer.pad_token_id] = -100  # Don't compute loss if predicting <PAD>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|>[Intro: Alfred Hitchcock]\n",
      "Thus far, this album has provided musical accompaniment to make your passing pleasant\n",
      "Our next number is designed to drown out the sound of shovels\n",
      "Music to be buried by<|endoftext|> \n",
      "\n",
      "tensor([[50257,    58,  5317,  ..., 50258, 50258, 50258],\n",
      "        [50257,    58,  1925,  ...,   502,   588,   645],\n",
      "        [50257,    58, 13414,  ...,     6,   329,   502],\n",
      "        ...,\n",
      "        [50257,    58, 13414,  ..., 50258, 50258, 50258],\n",
      "        [50257,    58,  5317,  ..., 50258, 50258, 50258],\n",
      "        [50257,    58,  5317,  ...,   460,   470,   345]])\n"
     ]
    }
   ],
   "source": [
    "print(train_songs[0], '\\n')\n",
    "print(train_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_input_ids, train_labels)\n",
    "\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 1  # To fit in GPU\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\",\n",
    "                                        output_attentions=False,\n",
    "                                        output_hidden_states=False,\n",
    "                                        )\n",
    "model.resize_token_embeddings(len(tokenizer))  # Since 2 new tokens for <BOS> and <PAD> were added to vocab\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124441344"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_trainable_params(model, print_shapes=False):\n",
    "    total_params = 0\n",
    "    for p in model.named_parameters():\n",
    "        if print_shapes:\n",
    "            print(p[0], p[1].shape)\n",
    "        total_params += torch.numel(p[1])\n",
    "    return total_params\n",
    "\n",
    "count_trainable_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, alpha, num_epochs, grad_clip=None, num_warmup_steps=0):\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=alpha)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, \n",
    "                                                num_training_steps=num_epochs*len(train_loader))\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        batch_losses = []\n",
    "        for batch_input_ids, batch_labels in tqdm(train_loader):\n",
    "            batch_input_ids, batch_labels = batch_input_ids.to(device), batch_labels.to(device)\n",
    "            \n",
    "            loss, _, _ = model(input_ids=batch_input_ids, labels=batch_labels, return_dict=False)\n",
    "            loss.backward()\n",
    "            if grad_clip:\n",
    "                clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "        epoch_loss = np.mean(batch_losses)\n",
    "        val_loss = evaluate(model, val_loader)\n",
    "        print(f\"Epoch: {e+1}, Train Loss: {epoch_loss}, Val Loss: {val_loss}\") \n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        batch_losses = []\n",
    "        \n",
    "        for batch_input_ids, batch_labels in val_loader:\n",
    "            batch_input_ids, batch_labels = batch_input_ids.to(device), batch_labels.to(device)\n",
    "            \n",
    "            loss, _, _ = model(input_ids=batch_input_ids, labels=batch_labels, return_dict=False)\n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "        return np.mean(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "alpha = 2e-5\n",
    "num_epochs = 5\n",
    "num_warmup_steps = 100\n",
    "grad_clip = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:55<00:00,  5.67it/s]\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 11.900276656348865, Val Loss: 3.3759586538587296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:55<00:00,  5.63it/s]\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 3.2542803835945007, Val Loss: 3.3808536938258578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:55<00:00,  5.61it/s]\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 3.123900361335316, Val Loss: 3.2485815184456963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:55<00:00,  5.60it/s]\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 3.0424137237353825, Val Loss: 3.2012113434927802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:55<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 2.9984559711937706, Val Loss: 3.2359492574419293\n",
      "CPU times: user 4min 25s, sys: 22.6 s, total: 4min 48s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit(model, train_loader, val_loader, alpha, num_epochs, grad_clip=grad_clip, num_warmup_steps=num_warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/vocab.json',\n",
       " './model/merges.txt',\n",
       " './model/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./model\")\n",
    "tokenizer.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"./model/\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./model/\")\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "prompt = tokenizer.bos_token\n",
    "prompt_id = tokenizer.batch_encode_plus([prompt], return_attention_mask=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "prompt_id = prompt_id.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|> [Intro]\n",
      "You wanna have a little break? Come on, do that.\n",
      "And if you can't, then that means I need to do a little math for ya.\n",
      "[Verse 1]\n",
      "I try to play on this notion that something is amiss\n",
      "By taking my daughter into a new world and having her do what I normally do and pretend as though she's smarter than I am\n",
      "For once she learns what I do and I can just shut her out.\n",
      "And that's when I know I can turn this crazy thing on again with an end of my career\n",
      "So I kick these old wounds away now and hope that their legacy is as strong as yours\n",
      "And, 'cause if they ever do come back, I'm gonna be a fool to think they will\n",
      "Not just throw a lot of cash at me, but start all over again\n",
      "To try and give back to this country, this neighborhood, and every single person that's touched it\n",
      "And see if they still cherish it, this past summer\n",
      "\n",
      "So that I can go again with what I always thought would be a fun adventure\n",
      "To try and build a new life in this old house\n",
      "With this place that I made last year, this family\n",
      "Then I put this whole thing aside and just keep living\n",
      "Now if you love this song, this song that I made this song, then maybe you'll\n",
      "Love it too\n",
      "\n",
      "[Chorus]\n",
      "You wanna be a rock star, bitch?\n",
      "Now I'm gonna build up and I'll try to get you\n",
      "A little bit of that fame and a little bit of fame\n",
      "And you wanna be a rock star, bitch?\n",
      "Now I'm gonna build up and I'll try to get you\n",
      "A little bit of that fame and a little bit of fame\n",
      "And you wanna be a rock star, bitch?\n",
      "\n",
      "[Verse 2]\n",
      "I was in a trance when I saw this big red brick wall and all it\n",
      "Was in the clouds and all I saw was white smoke and smoke\n",
      "And we were back in a trance\n",
      "And this bitch was a rock star\n",
      "And everybody was gonna love her in this room\n",
      "But I don't see how the fuck she could do this\n",
      "And I wouldn't do anything to stop it\n",
      "I just wanna have all the money I earned to buy her a little home\n",
      "And all I'd ever ask for was a little bit of fame\n",
      "But no, the man I would kill to sell her was \n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/blog/how-to-generate\n",
    "\n",
    "generated = model.generate(input_ids=prompt_id,\n",
    "                           max_length=512,\n",
    "                           do_sample=True,\n",
    "                           top_k=50,\n",
    "                           top_p=0.95,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           num_return_sequences=1\n",
    "                       )\n",
    "\n",
    "for song in tokenizer.batch_decode(generated):\n",
    "    print(song, \"\\n===========================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
